{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0afa7f1-2ac6-4353-90e8-cd85786842c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cophenet, fcluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac9480b-3c30-4720-8370-e70ce4f90faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"../../assets/huggingface_with_fairness.csv\" # <-- cámbialo\n",
    "OUTPUT_DIR = \"../../assets/cluster_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b3fba6-22dd-4da6-8bbc-f1cec1f9ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "\"performance_score\",\n",
    "\"co2_eq_emissions\",\n",
    "\"likes\",\n",
    "\"downloads\",\n",
    "\"size\",\n",
    "\"size_efficiency\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cb9611-d3bc-4f86-b0d0-a0fc5ed7ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTERNAL_LABELS = {\n",
    "\"tipo_modelo\": \"tipo_modelo\",\n",
    "\"clasificacion_fairness\": \"clasificacion_fairness\",\n",
    "\"es_justo\": \"es_justo\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eacf932-adca-4e89-9e1d-4a1cad571036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterios de corte (elige uno). Si ambos son None, se optimiza k por silueta en rango.\n",
    "K_TARGET: Optional[int] = None # p.ej., 3\n",
    "DIST_THRESHOLD: Optional[float] = None # p.ej., 1.2 (solo para métodos compatibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6983e870-e0dd-4355-8b89-0e687229f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango para búsqueda de k óptimo por silueta\n",
    "K_RANGE = range(2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875e15aa-8e6e-47d7-b30d-da55c0b7efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0db6032-5daf-4aca-986d-79a2c65d2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    name: str\n",
    "    distance: str # 'euclidean' | 'cosine' | 'mahalanobis'\n",
    "    linkage: str # 'ward' | 'average' | 'complete' | 'single'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1147bd-537d-449d-a673-4f2b8a18b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS: List[Config] = [\n",
    "    Config(\"Ward-Euclid\", \"euclidean\", \"ward\"), # ward solo con euclidiana\n",
    "    Config(\"Average-Euclid\", \"euclidean\", \"average\"),\n",
    "    Config(\"Complete-Euclid\", \"euclidean\", \"complete\"),\n",
    "    Config(\"Single-Euclid\", \"euclidean\", \"single\"),\n",
    "    Config(\"Average-Cosine\", \"cosine\", \"average\"),\n",
    "    Config(\"Complete-Cosine\", \"cosine\", \"complete\"),\n",
    "    Config(\"Single-Cosine\", \"cosine\", \"single\"),\n",
    "    Config(\"Average-Mahalanobis\", \"mahalanobis\", \"average\"),\n",
    "    Config(\"Complete-Mahalanobis\", \"mahalanobis\", \"complete\"),\n",
    "    Config(\"Single-Mahalanobis\", \"mahalanobis\", \"single\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f789e5c0-7b89-40d5-8633-fa6d56c84974",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365f8e8b-ce22-4be6-a520-b6aae04aa0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and processing\n",
    "def load_and_prepare(csv_path: str,\n",
    "    feature_cols: List[str],\n",
    "    alias: Dict[str, str],\n",
    "    external: Dict[str, str]) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    rename_map = {}\n",
    "    for col in df.columns:\n",
    "        if col in alias:\n",
    "            rename_map[col] = alias[col]\n",
    "    df = df.rename(columns=rename_map)\n",
    "    existing = set(df.columns)\n",
    "    fixed = []\n",
    "    for col in feature_cols:\n",
    "        if col in existing:\n",
    "            fixed.append(col)\n",
    "        else:\n",
    "            inv = {v: k for k, v in alias.items()}\n",
    "        if col in inv and inv[col] in existing:\n",
    "            fixed.append(inv[col])\n",
    "        else:\n",
    "            print(f\"[ADVERTENCIA] Columna no encontrada: {col}\")\n",
    "    feature_cols = fixed\n",
    "    \n",
    "    \n",
    "    # Variables externas si existen\n",
    "    ext_df = pd.DataFrame()\n",
    "    for k, v in external.items():\n",
    "        if v in df.columns:\n",
    "            ext_df[k] = df[v]\n",
    "        else:\n",
    "            print(f\"[INFO] Etiqueta externa no encontrada: {v}\")\n",
    "    \n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    \n",
    "    \n",
    "    for c in X.columns:\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    mask_valid = ~X.isna().any(axis=1)\n",
    "    rows_before = len(X)\n",
    "    X = X.loc[mask_valid]\n",
    "    ext_df = ext_df.loc[mask_valid]\n",
    "    print(f\"Filas eliminadas por NA/inf: {rows_before - len(X)}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    Z = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "    \n",
    "    \n",
    "    return df, Z, ext_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba8ae7d-cebf-4dde-b892-39ceedff4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4) Distancias y aglomeración\n",
    "# ============================\n",
    "\n",
    "\n",
    "def mahalanobis_pdist(Z: pd.DataFrame) -> np.ndarray:\n",
    "    X = Z.values\n",
    "    # Estima covarianza con Ledoit-Wolf (robusta) sobre Z\n",
    "    lw = LedoitWolf().fit(X)\n",
    "    VI = np.linalg.pinv(lw.covariance_)\n",
    "    d = pdist(X, metric=\"mahalanobis\", VI=VI)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "393a5f88-2084-4f64-aac1-2949adaa02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linkage(Z: pd.DataFrame, cfg: Config) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X = Z.values\n",
    "    if cfg.linkage == \"ward\":\n",
    "    # Ward requiere datos (no distancias) y equivale a euclidiana\n",
    "        L = linkage(X, method=\"ward\")\n",
    "        coph_dists = pdist(X, metric=\"euclidean\")\n",
    "    else:\n",
    "        if cfg.distance == \"euclidean\":\n",
    "            D = pdist(X, metric=\"euclidean\")\n",
    "        elif cfg.distance == \"cosine\":\n",
    "            D = pdist(X, metric=\"cosine\")\n",
    "        elif cfg.distance == \"mahalanobis\":\n",
    "            D = mahalanobis_pdist(Z)\n",
    "        else:\n",
    "            raise ValueError(\"Distancia no soportada\")\n",
    "    L = linkage(D, method=cfg.linkage)\n",
    "    coph_dists = D\n",
    "    return L, coph_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bca1aef-1aaa-4190-af8e-a5b0602fc459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_tree(L: np.ndarray,\n",
    "    k_target: Optional[int] = None,\n",
    "    dist_threshold: Optional[float] = None,\n",
    "    k_range = range(2, 9),\n",
    "    X_for_score: Optional[np.ndarray] = None) -> Tuple[np.ndarray, int, Optional[float], float]:\n",
    "    \"\"\"Devuelve labels, k elegido, threshold (si aplica) y silueta.\"\"\"\n",
    "    if dist_threshold is not None:\n",
    "        labels = fcluster(L, t=dist_threshold, criterion=\"distance\")\n",
    "        k = len(np.unique(labels))\n",
    "        sil = silhouette_score(X_for_score, labels, metric=\"euclidean\") if X_for_score is not None and k>1 else np.nan\n",
    "        return labels, k, dist_threshold, sil\n",
    "\n",
    "\n",
    "    if k_target is not None:\n",
    "        labels = fcluster(L, t=k_target, criterion=\"maxclust\")\n",
    "        sil = silhouette_score(X_for_score, labels, metric=\"euclidean\") if X_for_score is not None and k_target>1 else np.nan\n",
    "        return labels, k_target, None, sil\n",
    "    \n",
    "    \n",
    "    # Optimiza k por silueta en el rango\n",
    "    best = (-np.inf, None, None)\n",
    "    for k in k_range:\n",
    "        labels = fcluster(L, t=k, criterion=\"maxclust\")\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            continue\n",
    "        sil = silhouette_score(X_for_score, labels, metric=\"euclidean\") if X_for_score is not None else np.nan\n",
    "        if np.isnan(sil):\n",
    "            continue\n",
    "        if sil > best[0]:\n",
    "            best = (sil, k, labels)\n",
    "    if best[1] is None:\n",
    "        labels = fcluster(L, t=2, criterion=\"maxclust\")\n",
    "        sil = silhouette_score(X_for_score, labels, metric=\"euclidean\") if X_for_score is not None else np.nan\n",
    "        return labels, 2, None, sil\n",
    "    return best[2], best[1], None, best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0eba6a5-8af0-4698-a46d-0067c78c577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_external(labels: np.ndarray, ext_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "    out = {}\n",
    "    cl = pd.Series(labels, name=\"cluster\")\n",
    "    for name, col in ext_df.items():\n",
    "        try:\n",
    "            tab = pd.crosstab(cl, col)\n",
    "            out[name] = tab\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7424cfaa-4b75-4299-bcf8-36da475fe9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(csv_path: str = CSV_PATH):\n",
    "    df, Z, ext_df = load_and_prepare(csv_path, FEATURE_COLS, FEATURE_COLS, EXTERNAL_LABELS)\n",
    "    results = []\n",
    "        \n",
    "\n",
    "    \n",
    "    for cfg in CONFIGS:\n",
    "    # Ward solo tiene sentido con euclidiana\n",
    "        if cfg.linkage == \"ward\" and cfg.distance != \"euclidean\":\n",
    "            continue\n",
    "        try:\n",
    "            L, coph_d = compute_linkage(Z, cfg)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {cfg.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    # Cophenetic\n",
    "    coph_corr, _ = cophenet(L, coph_d)\n",
    "    \n",
    "    \n",
    "    # Dendrograma\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    dendrogram(L, no_labels=True)\n",
    "    plt.title(f\"Dendrograma – {cfg.name}\")\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(OUTPUT_DIR, f\"dendrogram_{cfg.name.replace(' ', '_')}.png\")\n",
    "    plt.savefig(fig_path, dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # Corte y evaluación\n",
    "    labels, k, thr, sil = cut_tree(L, K_TARGET, DIST_THRESHOLD, K_RANGE, Z.values)\n",
    "    \n",
    "    \n",
    "    # Resumen externo\n",
    "    ext_tabs = summarize_external(labels, ext_df)\n",
    "    \n",
    "    \n",
    "    # ARI vs es_justo (si es binaria y sin NA)\n",
    "    ari = np.nan\n",
    "    if \"es_justo\" in ext_df.columns:\n",
    "        y = ext_df[\"es_justo\"].dropna()\n",
    "        inter = np.intersect1d(y.index, Z.index)\n",
    "        if len(np.unique(y.loc[inter])) > 1:\n",
    "            ari = adjusted_rand_score(y.loc[inter].astype(int), pd.Series(labels, index=Z.index).loc[inter])\n",
    "        \n",
    "        \n",
    "        # Guardar tablas externas\n",
    "    ext_paths = {}\n",
    "    for name, tab in ext_tabs.items():\n",
    "        p = os.path.join(OUTPUT_DIR, f\"tabla_{cfg.name.replace(' ', '_')}_{name}.csv\")\n",
    "        tab.to_csv(p)\n",
    "        ext_paths[name] = p\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "    \"config\": cfg.name,\n",
    "    \"distance\": cfg.distance,\n",
    "    \"linkage\": cfg.linkage,\n",
    "    \"cophenetic\": coph_corr,\n",
    "    \"k\": k,\n",
    "    \"threshold\": thr,\n",
    "    \"silhouette\": sil,\n",
    "    \"ari_vs_es_justo\": ari,\n",
    "    \"dendrogram_path\": fig_path,\n",
    "    \"external_tables\": ext_paths,\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # Ranking por silueta y cophenético\n",
    "    res_df = pd.DataFrame(results)\n",
    "    if not res_df.empty:\n",
    "        res_df = res_df.sort_values([\"silhouette\", \"cophenetic\"], ascending=False)\n",
    "        res_path = os.path.join(OUTPUT_DIR, \"resumen_configuraciones.csv\")\n",
    "        res_df.to_csv(res_path, index=False)\n",
    "        print(\"\\nResumen guardado en:\", res_path)\n",
    "        print(\"\\nTop configuraciones (por silueta, luego cophenético):\\n\")\n",
    "        print(res_df.head(10))\n",
    "        print(\"\\nDendrogramas y tablas por configuración en:\", os.path.abspath(OUTPUT_DIR))\n",
    "    else:\n",
    "        print(\"No se pudo generar ningún resultado. Verifica columnas y datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983aea4c-f994-400e-b331-cab912605e33",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(csv_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_pipeline\u001b[39m(csv_path: \u001b[38;5;28mstr\u001b[39m = CSV_PATH):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df, Z, ext_df = \u001b[43mload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFEATURE_COLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFEATURE_COLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEXTERNAL_LABELS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     results = []\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cfg \u001b[38;5;129;01min\u001b[39;00m CONFIGS:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Ward solo tiene sentido con euclidiana\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mload_and_prepare\u001b[39m\u001b[34m(csv_path, feature_cols, alias, external)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m alias:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         rename_map[col] = \u001b[43malias\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m df = df.rename(columns=rename_map)\n\u001b[32m     13\u001b[39m existing = \u001b[38;5;28mset\u001b[39m(df.columns)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "run_pipeline(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d333d54-6218-48fe-8121-e00a0e209c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../assets/huggingface_with_fairness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f19dfd-f0a4-4a36-a078-2e29f908435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['performance_score', 'co2_eq_emissions', 'size', 'si]\n",
    "df_cluster = df[features].dropna() # Usar .dropna() para eliminar filas con datos faltantes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
